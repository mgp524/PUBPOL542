{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"http://i.imgur.com/sSaOozN.png\" width=\"500\"></center>\n",
    "\n",
    "## Course: Computational Thinking for Governance Analytics\n",
    "\n",
    "### Prof. José Manuel Magallanes, PhD \n",
    "* Visiting Professor of Computational Policy at Evans School of Public Policy and Governance, and eScience Institute Senior Data Science Fellow, University of Washington.\n",
    "* Professor of Government and Political Methodology, Pontificia Universidad Católica del Perú. \n",
    "\n",
    "_____\n",
    "\n",
    "<a id='home'></a>\n",
    "\n",
    "# Data Preprocessing in Python: Data Integration and Reshaping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will cover some important processes for DFs:\n",
    "* [Appending](#appending)\n",
    "* [Reshaping](#reshaping)\n",
    "* [Merging](#merging)\n",
    "\n",
    "Finally, we will see some simple code for:\n",
    "* [Scaling](#scaling)\n",
    "* [Exporting](#exporting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='appending'></a>\n",
    "\n",
    "# Appending\n",
    "\n",
    "As the name implies, this process binds DFs into one, that is, one or more DFs will be put below or on top of another DF. Appending can be done when you fulfill these requisites:\n",
    "1. All the DFs  share the same column names.\n",
    "2. All the DFs  columns are in the same location.\n",
    "2. All the DFs  columns have the same data types.\n",
    "\n",
    "Let's visit this website: https://fundforpeace.org/what-we-do/country-risk-and-fragility-data/\n",
    "\n",
    "There, you will find several excel files with the _Fragile States Index_ per year. Let's downloan the ones for years 2019-2021 in the folder where this notebook is stored. Then, we can open them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file2021=\"fsi-2021.xlsx\"\n",
    "file2020=\"fsi-2020.xlsx\"\n",
    "file2019=\"fsi-2019.xlsx\"\n",
    "    \n",
    "\n",
    "# fetching the tables\n",
    "fragil2021=pd.read_excel(file2021)\n",
    "fragil2020=pd.read_excel(file2020)\n",
    "fragil2019=pd.read_excel(file2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to append all of them. \n",
    "\n",
    "In the next operations, I will use **sets**. Let me show you how they work with simple examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A=['a','b','c']\n",
    "B=['a','b','d','c']\n",
    "C=['a','b','e','g']\n",
    "\n",
    "# set intersection\n",
    "set(A) & set(B) & set(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, using set I can verify that condition 1 is fulfilled:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are the columns shared among the DFs\n",
    "set(fragil2021.columns)&set(fragil2020)&set(fragil2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This intersection is offering me a particular order, then you can create DFs with columns located in that same order, which will allow us to fulfill the second condition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common=set(fragil2021.columns)&set(fragil2020)&set(fragil2019)\n",
    "\n",
    "# we are keeping just the 'common' columns:\n",
    "fragil2021ap=fragil2021.loc[:,common]\n",
    "fragil2020ap=fragil2020.loc[:,common]\n",
    "fragil2019ap=fragil2019.loc[:,common]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last requisite is to make sure they share the same data types. Let's check the data types with the help of **zip**, **set** and **len**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A=['a','b','c']\n",
    "B=['a','b','c']\n",
    "C=['a','b','d']\n",
    "\n",
    "# zip will pair elements in the same position:\n",
    "list(zip(A,B,C))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining _len_ and _set_ you have a measure of 'variety'. If variety of a _set_ equals **1**, all the elements in a _set_ are the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set([1,1,1,1,1,1,1,1,1,1])), \\\n",
    "len(set([1,2,1])), \\\n",
    "len(set([1,111,11]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, you detect where a group does not have the same elements, that is, where the set size offers a variety greater than one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if every zipped group has a variety greater than 1.\n",
    "[x for x in zip(A,B,C) if len(set(x))>1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying that to our case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. the zipped data types:\n",
    "theZips=zip(fragil2021ap.dtypes,\n",
    "            fragil2020ap.dtypes,\n",
    "            fragil2019ap.dtypes)\n",
    "# you see:\n",
    "list(theZips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. computing the variety in each case above:\n",
    "theZips=zip(fragil2021ap.dtypes,\n",
    "            fragil2020ap.dtypes,\n",
    "            fragil2019ap.dtypes) # why again? zip is generator\n",
    "[x for x in theZips if len(set(x))>1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the result above, there is one set of columns that share different data types. Let me modify the previous code to detect the location:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theZips=zip(fragil2021ap.dtypes.index,\n",
    "            fragil2021ap.dtypes,\n",
    "            fragil2020ap.dtypes,\n",
    "            fragil2019ap.dtypes)\n",
    "\n",
    "[x for x in theZips if len(set(x))>2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Year is not an integer in the DFs for 2020 and 2019, it is **date** type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragil2020ap['Year']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the **dt** attribute of a **date** column in Pandas, we can recover just the year as an integer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragil2020ap['Year']=fragil2020ap['Year'].dt.year\n",
    "fragil2019ap['Year']=fragil2019ap['Year'].dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it should be fine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if empty list, all dtypes are the same\n",
    "theZips=zip(fragil2021ap.dtypes,fragil2020ap.dtypes,fragil2019ap.dtypes)\n",
    "[x for x in theZips if len(set(x))>1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have met al the requisites, let's do the appending!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragile=pd.concat([fragil2021ap,fragil2020ap,fragil2019ap])\n",
    "fragile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may notice that the column ordering does not look nice, as in general you expect that the columns to the left start with identification of the rows rather than some measurements; then, let's move 'Country','Year','Total' to the left:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a trick: setting columns as index\n",
    "fragile.set_index(['Country','Year','Total'],inplace=True)\n",
    "fragile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since I will not use _Rank_, I will get rid of it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragile.drop(columns='Rank',inplace=True)\n",
    "fragile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now put the row indexes back:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragile.reset_index(inplace=True)\n",
    "fragile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do some cleaning on the column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragile.columns=fragile.columns.str.replace(':|\\s',\"\",regex=True)\n",
    "#see\n",
    "fragile.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's check the format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragile.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Home](#home)\n",
    "\n",
    "______\n",
    "\n",
    "<a id='reshaping'></a>\n",
    "\n",
    "# Reshaping\n",
    "\n",
    "Data frames have have different shapes. Let me keep some columns from the last DF so you can notice something:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragileLong=fragile.iloc[:,:3]\n",
    "fragileLong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The unit of analysis is country. Generally, we are used to see the  unit of analysis once in a column, but it is repeated above, as the country will appear for every year of measurement.\n",
    "\n",
    "Also, pay attention to the **amount of rows**. There are 535 rows, then:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "535/3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is the amount of rows per data year, so something went wrong during the appending. The truth is that cleaning and formatting will be needed after complex operations like these.\n",
    "\n",
    "What is your best guess on what went wrong?\n",
    "\n",
    "Whatever it is, let me turn our **long** into **wide** shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wide\n",
    "fragileWide=pd.pivot_table(fragileLong,\n",
    "               values='Total', # values to use\n",
    "               index=['Country'], # unit of analysis\n",
    "               columns=['Year']) # the values for NEW column\n",
    "fragileWide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **wide** shape from a **pivot_table** function looks great, but pay attention:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragileWide.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you see above, the country is an _index_, not a column. This is important if you are planing to export this DF. Also, notice that the column names have a title (_Year_). So in general, you can use this code after the *pivot_table* function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragileWide= fragileWide.reset_index(drop=False).\\\n",
    "             rename_axis(index=None, columns=None)\n",
    "\n",
    "# result:\n",
    "\n",
    "fragileWide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I mentioned that something went wrong during the appending process. Here, we can discover it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what cells have missing values?\n",
    "fragileWide[fragileWide.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, even though the data DFs were prepared by the same [organization](https://fundforpeace.org/), the DFs have country names that differ among them. Here we need some **manual** changes: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare changes as dict:\n",
    "changes={\"Cabo Verde\": \"Cape Verde\",\n",
    "\"Czechia\":\"Czech Republic\",\n",
    "\"Swaziland\":\"Eswatini\",\n",
    "\"Israel and West Bank\":\"Israel\",\n",
    "\"Kyrgyzstan\":\"Kyrgyz Republic\",\n",
    "\"North Macedonia\":\"Macedonia\",\n",
    "\"Slovakia\": \"Slovak Republic\"}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice I had to make the changes in the long shape of the DF, so that the wide shape will work fine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make changes using 'replace':\n",
    "fragileLong.Country.replace(to_replace=changes,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's redo the wide reshape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wide\n",
    "fragileWide=pd.pivot_table(fragileLong,\n",
    "               values='Total',\n",
    "               index=['Country'],\n",
    "               columns=['Year']).\\\n",
    "            reset_index(drop=False).\\\n",
    "            rename_axis(index=None, columns=None)\n",
    "##\n",
    "fragileWide[fragileWide.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have to be very careful when working with countries, specially when you are including or excluding countries; which may cause you hurting someone else's feelings. \n",
    "\n",
    "For instance, here I am just keeping **rows** with no missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragileWide.dropna(inplace=True) # axis=1 for columns\n",
    "fragileWide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, notice that the final line above says that the last row index is 178; which means there are 179 rows. To correct that, reset the index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragileWide.reset_index(drop=True, inplace=True)\n",
    "fragileWide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For sure, we can turn this wide format into a long one, using the function **melt**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.melt(fragileWide, id_vars=['Country'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This would be more explicit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.melt(fragileWide, #DF\n",
    "        id_vars=['Country'], #key\n",
    "        value_vars=[2019,2020,2021], # columns in wide\n",
    "        var_name='Year', # new name for long column\n",
    "        value_name='Total')# new name for values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Home](#home)\n",
    "\n",
    "______\n",
    "\n",
    "<a id='merging'></a>\n",
    "\n",
    "# Merging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging data sets need the following considerations:\n",
    "\n",
    "* Merging is done on two data frames.\n",
    "* You need a column in each data frame that share the same exact and unique values. The column names or titles need not be the same.\n",
    "* The merged table shows by default the mutual coincidences; but you can also request the values not matched, which will help you detect possible extra cleaning.\n",
    "* Pandas differentiates the **left** from the **right** data frames: **left**.merge(**right**).\n",
    "\n",
    "At this stage, let me use two data frames to show how this works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo=pd.read_pickle(\"https://github.com/EvansDataScience/CTforGA_cleaning/raw/main/demoindex.pkl\")\n",
    "#and\n",
    "fragile2021=fragile[fragile.Year==2021].drop(columns=['Year'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember the amount of rows of each DF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo.shape,fragile2021.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let me show you some merge approaches, but only the amount of columns produced:\n",
    "\n",
    "1. You keep only what is common in both key columns:\n",
    "\n",
    "This is the default. The final rows will be the ones where the key values in each data frame match exactly. In this case, your count of rows will be at most the amount of rows of the smallest data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragile2021.merge(demo).shape  # how=inner - this is the default "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. You keep all the keys from the left/right:\n",
    "\n",
    "The final rows will be all the rows from the dataframe from the left. If a key values does not find a match, the key value is kept, but the columns will have missing values. In this case, your count of rows will be equal to the amount of rows of the data frame to the left. You can also use **right** so the same logic applies to the data frame to the right.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragile2021.merge(demo, how='left').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragile2021.merge(demo, how='right').shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. You keep all the rows from both data frames:\n",
    "\n",
    "In this case you will obtain all possible rows: the matched values, and the unmatched values from both data frames. You will also generate missing values. In this case, your count of rows will be at least the amount of rows of the data frame with the most rows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragile2021.merge(demo, how='outer').shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the default case for now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo.merge(fragile2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you see less rows than the data frame with the least rows, you wnt to know **what does not match** between the key columns. Let's use set operations to find what countries are not matching:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Countris in 'demo' but NOT in 'fragile2021' \n",
    "OnlyDemo=set(demo.Country)-set(fragile2021.Country)\n",
    "OnlyDemo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Countris in 'fragile2021' but NOT in 'demo' \n",
    "OnlyFragile=set(fragile2021.Country)-set(demo.Country)\n",
    "OnlyFragile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we should try to find the what countries in _OnlyFragile_ may match the ones in _OnlyDemo_. We need to use the **fuzzy merge** approach (please install **thefuzz** if not previously installed):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thefuzz import process as fz\n",
    "\n",
    "# take a country from OnlyDemo\n",
    "# look for a country in OnlyFragile and return the most similar\n",
    "[(fz.extractOne(demo, OnlyFragile),demo) for demo in sorted(OnlyDemo)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above you have found _some_ good matches. As you see the ones that are wrong have  less than 95% match. Let's just keep those:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(fz.extractOne(demo, OnlyFragile),demo) \n",
    " for demo in sorted(OnlyDemo) \n",
    " if fz.extractOne(demo, OnlyFragile)[1]>=95]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have good matches, you have to create dictionary like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "changesFragile1={fz.extractOne(demo, OnlyFragile)[0]:demo \n",
    "                 for demo in sorted(OnlyDemo) \n",
    "                 if fz.extractOne(demo, OnlyFragile)[1]>=95}\n",
    "#dict of matches\n",
    "changesFragile1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use that dict for the replacements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragile2021.Country.replace(to_replace=changesFragile1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the countries in fragile2021 have more matches. \n",
    "\n",
    "This process can be done a few more times, and you can recover more rows for the merging process. Let's see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second try\n",
    "OnlyDemo=set(demo.Country)-set(fragile2021.Country)\n",
    "OnlyFragile=set(fragile2021.Country)-set(demo.Country)\n",
    "[(fz.extractOne(demo, OnlyFragile),demo) for demo in sorted(OnlyDemo)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second dict of changes\n",
    "# select a different threshold\n",
    "changesFragile2={fz.extractOne(demo, OnlyFragile)[0]:demo \n",
    "                 for demo in sorted(OnlyDemo) \n",
    "                 if fz.extractOne(demo, OnlyFragile)[1]>=80}\n",
    "#dict of matches\n",
    "changesFragile2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the changes\n",
    "fragile2021.Country.replace(to_replace=changesFragile2,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# third try\n",
    "OnlyDemo=set(demo.Country)-set(fragile2021.Country)\n",
    "OnlyFragile=set(fragile2021.Country)-set(demo.Country)\n",
    "[(fz.extractOne(demo, OnlyFragile),demo) for demo in sorted(OnlyDemo)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# third dict of changes\n",
    "# new threshold\n",
    "changesFragile3={fz.extractOne(demo, OnlyFragile)[0]:demo \n",
    "                 for demo in sorted(OnlyDemo) \n",
    "                 if fz.extractOne(demo, OnlyFragile)[1]>=64}\n",
    "#dict of matches\n",
    "changesFragile3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make changes\n",
    "fragile2021.Country.replace(to_replace=changesFragile3,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fourth try\n",
    "\n",
    "OnlyDemo=set(demo.Country)-set(fragile2021.Country)\n",
    "OnlyFragile=set(fragile2021.Country)-set(demo.Country)\n",
    "[(fz.extractOne(demo, OnlyFragile),demo) for demo in sorted(OnlyDemo)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fourth attempt did not offer good results. Those two countries will not be able to be matched. Let's retry the merge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_fragile=demo.merge(fragile2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking:\n",
    "demo_fragile.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging is a key process for producing analytics. So, it is always good to add some 'standard' information to avoid the need of fuzzy merging. See this data table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isos='https://github.com/EvansDataScience/CTforGA_integrating/raw/main/isodata.csv'\n",
    "isodata=pd.read_csv(isos)\n",
    "isodata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should add the **ISO** columns to our recent merged data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# key columns are not spelled the same:\n",
    "\n",
    "isodata.merge(demo_fragile,right_on='Country', left_on='Countryname')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems I need five more:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_fragile.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let;s find this time **ALL** the matches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onlyDEF=set(demo_fragile.Country)-set(isodata.Countryname)\n",
    "onlyISO=set(isodata.Countryname)-set(demo_fragile.Country)\n",
    "\n",
    "[(demo,fz.extract(demo, onlyISO)) for demo in sorted(onlyDEF)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's prepare manually the dictionary of replacements:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moreChanges={'Czech Republic':'Czechia',\n",
    "             'Laos':\"Lao People's Democratic Republic (the)\",\n",
    "             'North Korea':\"Korea (the Democratic People's Republic of)\",\n",
    "             'Republic of the Congo':'Congo (the)',\n",
    "             'South Korea':'Korea (the Republic of)'}\n",
    "demo_fragile.Country.replace(to_replace=moreChanges,inplace=True)\n",
    "# merging\n",
    "demfragiso=isodata.merge(demo_fragile,\n",
    "                         right_on='Country',\n",
    "                         left_on='Countryname')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pay attention to this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demfragiso.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that you have this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demfragiso.loc[:,['Countryname','Country']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could get rid of the repeated column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demfragiso.drop(columns=['Country'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Home](#home)\n",
    "\n",
    "\n",
    "______\n",
    "\n",
    "<a id='scaling'></a>\n",
    "\n",
    "\n",
    "# Data Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It all look great so far. However, once you think you have the data ready, you should see the data ranges:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demfragiso.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **describe** will only show numerical stats by default, so you need the parameter _include_ set to *all*. However, for our case, we should just request the range:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demfragiso.describe().loc[['min','max']].T # notice the transposing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A boxplot may also be helpful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "demfragiso.plot(kind='box', rot=90)\n",
    "plt.semilogy();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you see above, the **Total** has a range of values different than the rest. Let's make sure all numeric columns share the same range:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# prepare the process\n",
    "scaler = preprocessing.MinMaxScaler(feature_range=(0, 10))\n",
    "# scaler = preprocessing.MinMaxScaler() default is 0 to 1\n",
    "\n",
    "# apply process\n",
    "columnsToScale=['Total'] # you can add more columns\n",
    "scaledResult = scaler.fit_transform(demfragiso[columnsToScale])\n",
    "\n",
    "# result\n",
    "scaledResult"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You just got:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(scaledResult)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let me use that array to replace my values in the pandas _Series_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demfragiso.Total=scaledResult"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, these are my new data values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demfragiso.plot(kind='box', rot=90);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative would have been to create a new column, so that you can keep the old value instead of overwriting it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#demfragiso['Total_mM']=scaledResult"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is ready to be exported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demfragiso_expo=demfragiso.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "[Home](#home)\n",
    "\n",
    "\n",
    "______\n",
    "\n",
    "<a id='exporting'></a>\n",
    "\n",
    "\n",
    "# Exporting file\n",
    "\n",
    "The current *demo_fragile* data frame is clean and formatted. It is time to send it to a format that will keep all our work for future use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For future use in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demfragiso_expo.to_pickle(\"demfragiso_expo.pkl\")\n",
    "# you will need: DF=pd.read_pickle(\"demfragiso_expo.pkl\")\n",
    "# or:\n",
    "# from urllib.request import urlopen\n",
    "# DF=pd.read_pickle(urlopen(\"https://..../demfragiso_expo.pkl\"),compression=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For future  use in R:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try the following before starting Python:\n",
    "#export LD_LIBRARY_PATH=\"$(python -m rpy2.situation LD_LIBRARY_PATH)\":${LD_LIBRARY_PATH}\n",
    "\n",
    "from rpy2.robjects import pandas2ri\n",
    "pandas2ri.activate()\n",
    "\n",
    "from rpy2.robjects.packages import importr\n",
    "\n",
    "base = importr('base')\n",
    "base.saveRDS(demfragiso_expo,file=\"demfragiso_expo.RDS\")\n",
    "\n",
    "\n",
    "#In R, you call it with: DF = readRDS(\"demfragiso_expo.RDS\")\n",
    "#or, if iyou read from cloud: DF = readRDS(url(\"https://..../demfragiso_expo.RDS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
